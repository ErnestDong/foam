---
tags: DeepLearning
---

# 模型压缩

## 低比特量化

将高精度的数转化为低精度。量化方法有：

- QAT：训练时量化。插入伪量化节点，找到数据的分布、模拟量化带来的损失
- PTQ：训练后量化。
  - 动态 PTQ 性能比较差，直接把`fp32`的权重转化为`int8`
  - 静态 PTQ 被大多数推理引擎使用，使用 KL 散度等方法找到最优的量化参数

大多数模型训练时会用混合精度训练，即保存`fp32`的权重，但是在训练过程中使用`fp16`计算梯度等信息，再在更新时更新`fp32`的权重

## 剪枝

大的稀疏模型比小的稠密模型要好，因此可以训练一个大的稠密模型，然后剪枝掉一些不重要的权重，得到一个大稀疏模型，节约资源。剪枝算法可以粗略分为：

- 非结构化剪枝：随机对独立的权重进行剪枝
- 结构化剪枝：对 filter/channel/layer 进行剪枝

剪枝的流程可以是：

- 训练、剪枝、然后 fine-tuning
- 边训练边剪枝，然后 fine-tuning
- 剪枝完成后，重新训练

> L1-norm 剪枝：对每个 filter 求 L1-norm，绝对值和比较小说明该 filter 不重要，可以剪掉

## 知识蒸馏

将教师网络的知识蒸馏到学生网络中，学生网络的参数更少，但是能够达到教师网络的精度。蒸馏的方法有：

- Response Based：让 Student 的输出和 Teacher 的输出尽可能接近
- Feature Based：让 Student 的某些中间层输出和 Teacher 的某些中间层输出尽可能接近
- Relation Based：学习数据样本和网络模型层之间的关系
- Architecture Based：很少用

> Hinton 经典蒸馏算法
