---
tags: DeepLearning
---
# Deep Q-Network

用[[神经网络]]近似 $Q^*(s_t,a_t)$ 函数，
进而得到 $a=\argmax_{a} Q^*(s,a)$ 来决策。
用神经网络 $Q(s_t,a_t;w)$ 来打分

## TD(temporal difference learning)

传统梯度下降需要完成整个过程才能求 loss，TD 算法利用了部分完成时的信息。部分完成时的真实值 y 和两次预测值的差，这两个数值的差称为 TD error $\delta$，神经网络来最小化$\delta$

强化学习中存在
$$
Q(s_t,a_t;w) \approx reward_t + \gamma Q(s_{t+1},a_{t+1};w)
$$
因而可以采用 TD 算法来优化

[//begin]: # "Autogenerated link references for markdown compatibility"
[神经网络]: ../concept/神经网络.md "神经网络"
[//end]: # "Autogenerated link references"
