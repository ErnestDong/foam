---
tags: devops
---

# Spark

是一个计算引擎，相较于 [[MapReduce]]，通过内存来提高计算速度，并提供了`map`和`reduce`之外的更多算子

## 模块

- Spark Core：Spark 的核心模块，提供了 Spark 的基本功能，包括任务调度、内存管理、RDD 等
- 基于 Spark Core 的其他模块

  - Spark SQL 通过 Catalyst 优化器将 SQL 语句转换为 Spark 任务
  - Spark Streaming：流式计算
  - MLlib：机器学习
  - GraphX：图计算

## 架构

- RDD：是弹性分布式数据集 Resilient Distributed Dataset 的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型。
  - 宽依赖：父 RDD 和子 RDD 之间是一对多或多对多的关系，需要 shuffle
  - 窄依赖：相互依赖的 RDD 不是宽依赖，不需要 shuffle
  - shuffle：通过一个 Patitioner 函数将父 RDD 中每个分区上 key 不同的记录分发到不同的子 RDD 分区。
- DAG：有向无环[[图]]，反映 RDD 之间的依赖关系。

RDD 之间的依赖关系形成一个 DAG 有向无环图，DAG 会提交给 DAGScheduler，DAGScheduler 会把 DAG 划分成相互依赖的多个 stage，划分 stage 的依据就是 RDD 之间的宽窄依赖。
遇到宽依赖就划分 stage,每个 stage 包含一个或多个 task 任务。然后将这些 task 以 taskSet 的形式提交给 TaskScheduler 运行。

[//begin]: # "Autogenerated link references for markdown compatibility"
[mapreduce]: ../hadoop/MapReduce.md "MapReduce @dean2008mapreduce"
[图]: ../../algorithm/data_structure/图.md "图"
[//end]: # "Autogenerated link references"
