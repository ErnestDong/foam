---
tags: DeepLearning
bibliography: [../../reference.bib]
---

# Transformer

## [[attention]]

## transformer

### encoder

多层 block 来组成[[神经网络]]，输入一个向量输出一个向量，输入向量有多长输出就有多长

每个 block

- 先做 self-attention，然后 add&norm 。所谓 add ，其 output 结果再加上输入的向量（称为 residual connection ），所谓 norm 做 layer normalization （(x-mean)/std） ，
- 然后 fully connect 并再次 add&norm

### decoder

decoder 看到的输入是输入（输入=begin token + output embedding）加上前一个 decoder 的输出

block 和 encoder 的区别在于：

- self-attention 加 mask。所谓 mask 是指产生输出的时候不能看后面的输入，因为 decoder 是一个个输入的，训练为了并行化输入结果因而需要 mask
- 中间夹了一层 cross-attention ，连接 encoder 和 decoder

decoder 可以自己决定输出的长度，方法是输出 token 为 end 时候停止

### encoder-decoder

q 来自 decoder ，k 和 v 来自 encoder ，做 attention 作为 cross-attention

## 应用

- [[BERT]]：预训练的带掩码的大模型，Encoder-only
- [[GPT]]：预训练的大型，Decoder-only
- [[ViT]]：transformer 在 CV 中的应用
- [[Swin]]：移动窗口的 attention
- [[CLIP]]：多模态学习

[//begin]: # "Autogenerated link references for markdown compatibility"
[attention]: transformer/attention.md "Attention"
[神经网络]: %E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md "神经网络"
[BERT]: ../model/BERT.md "BERT"
[GPT]: ../model/GPT.md "GPT"
[ViT]: ../model/ViT.md "ViT"
[Swin]: ../model/Swin.md "Swin"
[CLIP]: ../model/CLIP.md "CLIP"
[//end]: # "Autogenerated link references"
