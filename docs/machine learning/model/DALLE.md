---
tags: DeepLearning
bibliography: [../../reference.bib]
---

# DALL E 2

基于[[CLIP]]的扩散模型，有取代[[GAN]]的趋势，有“创造力”。过程是

- prior：给定文本描述生成图像特征
- decoder：从特征生成图像

## 扩散模型

前向扩散过程：给图片加小的噪声 t 次，趋近无穷时趋于噪声
反向生成：模型反向去噪声生成图片，预测噪声有哪些([[CNN]]里面的 ResNet)。模型里面加 time embedding，并且共享参数。

## ControlNet

通过“控制”让 AI 会调整图，控制的方式可以是：

- edge map：提取出来形状的线稿
- segmentation map：分割图
- keypoints：关键点

[//begin]: # "Autogenerated link references for markdown compatibility"
[CLIP]: CLIP.md "CLIP"
[GAN]: ../concept/GAN.md "GAN"
[CNN]: ../concept/CNN.md "CNN"
[//end]: # "Autogenerated link references"
