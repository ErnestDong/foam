---
tags: python
---
# 爬虫

## requests

a [[python]] library for [[爬虫]]

### response 对象

常用属性

| url             | 获得响应的 url      |
| --------------- | ------------------- |
| request.headers | header(my)          |
| headers         | 响应头(the website) |
| cookies         | Cookie Jar          |

1.  headers

    `requests.get(url, headers={"User-Agent":"abc"})`

### 发送带参数的请求

1.  直接在 url 中携带参数

2.  param 携带参数字典

    例如
    
    ```python
    res = requests.get("https://baidu.com/s?", headers=headers, param={"wd": "abc"})
    ```

### cookie

存在本地，浏览器有数量限制（4k）

1.  headers 中携带 cookie

    ```python
    headers["Cookie"]="cookie"
    ```

2.  cookie 参数保持会话

    `requests.get(url,cookies={key1:value1,key2:value2})`

3.  `requests.utils`

    ```python
    # cookiejar to dict
    requests.utils.dict_from_cookiejar(response.cookie)
    
    ```

### session

自动处理 cookie，存在服务器上

request 的 session 可以自动携带之前的 cookie

```python
session = requests.session()

response = session.get(url)
```

### 代理

构造 response 对象时传入 `proxies={"http":"http://127.0.0.1:7890"}`

### [[javascript]] 加密

-   选择会触发 js 加密的按钮，在 event listener 中找到 js 位置
-   给 js 打断点解密传输的到底是什么，改写成 python。

### http method

http is stateless

1.  get 方法

    网址有?，其后就是我们发了一个 get 请求
    
    是拿取资料

2.  post 方法

    发送资料

3.  put

    覆盖

4.  patch

    更新

5.  delete

    删除

### 403 错误

添加 `referrer`

### websockets

通过 http 1.1 引入的 persistent TCP 传输数据，是 stateful 的二进制的数据

协议是 ws:// or wss:// ，关系类似 http or https

## aiohttp

使用异步 [[协程]]加速

## 用 `js2py` 解析 [[javascript]] 加密
